{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "da43a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import requests\n",
    "from goose3 import Goose\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "from gather_news import create_company_articles_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b45dffb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fff53b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWS_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76246dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Publish date Published: Feb. 14, 2023 at 12:10 p.m. ET could not be resolved to UTC\n",
      "Publish date on Monday January 30, 2023 @05:02PM could not be resolved to UTC\n",
      "Publish date Last Updated: Jan. 28, 2023 at 9:49 a.m. ET could not be resolved to UTC\n"
     ]
    }
   ],
   "source": [
    "create_company_articles_workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f7e52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_excel('sample_fine_tune.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ae7e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for rate limit exponential delay\n",
    "def ratelimiterror_exponential_backoff(\n",
    "    func,\n",
    "    init_delay=60,\n",
    "    expo_base=2,\n",
    "    errors=(openai.error.RateLimitError),\n",
    "    max_retries=5\n",
    "):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        retries = 0\n",
    "        delay = init_delay\n",
    "        while True:\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except errors as e:\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    raise Exception(f'Exceeded maximum number of retries ({max_retries})')\n",
    "                    \n",
    "                print(f'RateLimitError: Sleeping for {delay} seconds')\n",
    "                time.sleep(delay)\n",
    "                delay *= expo_base\n",
    "                print(f'Next error wait time is {delay} seconds. {max_retries - retries} retries remaining')\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                raise e\n",
    "    return wrapper\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "993c4f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ratelimiterror_exponential_backoff\n",
    "def generate_questions(prompt):\n",
    "    wait_time = 3.5\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt=f'Write three questions based on the article below\\nArticle: {prompt}\\nQuestions:\\n1.',\n",
    "        presence_penalty=0.5,\n",
    "        frequency_penalty=0.5,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_tokens=750,\n",
    "        stop=['\\n\\n']\n",
    "    )\n",
    "    time.sleep(wait_time)\n",
    "    questions = '1.' + response['choices'][0]['text']\n",
    "    return questions, response\n",
    "\n",
    "@ratelimiterror_exponential_backoff\n",
    "def generate_answers(context, questions):\n",
    "    wait_time = 3.5\n",
    "    response = openai.Completion.create(\n",
    "        model='text-davinci-003',\n",
    "        prompt=f'Write answers to the questions based on the article below\\nQuestions:\\n{questions}\\n\\nArticle: {context}\\n\\nAnswers:\\n1.',\n",
    "        presence_penalty=0.5,\n",
    "        frequency_penalty=0.5,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        max_tokens=750,\n",
    "    )\n",
    "    time.sleep(wait_time)\n",
    "    answers = '1.' + response['choices'][0]['text']\n",
    "    return answers, response\n",
    "\n",
    "def generate_prompt(context, questions):\n",
    "    return f'Write answers to the questions based on the article below\\nQuestions:\\n{questions}\\n\\nArticle: {context}\\n\\nAnswers:\\n1.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ff74df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trimmed_articles(df):\n",
    "\tdef split_article(title, date, timeout, content):\n",
    "\t\tif timeout:\n",
    "\t\t\treturn None\n",
    "\t\theader = f'{title}\\n{date}\\n'\n",
    "\t\tprompts = []\n",
    "\t\tdivs = len(content) // 4000\n",
    "\t\tfor _ in range(divs):\n",
    "\t\t\tdiv = ''\n",
    "\t\t\twhile len(div) < 4000:\n",
    "\t\t\t\tnewline_index = content.find('\\n')\n",
    "\t\t\t\tcut = content[:newline_index]\n",
    "\t\t\t\tdiv += cut + '\\n'\n",
    "\t\t\t\tcontent = content[newline_index + 1:]\n",
    "\t\t\t\n",
    "\t\t\tprompts.append(header + div)\n",
    "\t\tprompts.append(header + content)\n",
    "\t\treturn pd.Series(prompts)\n",
    "\t\n",
    "\tresp = articles.apply(lambda row: split_article(row['title'], row['date_published'], row['timeout'], row['content']), axis=1)\n",
    "\treturn resp.melt(value_name='content').drop('variable', axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4cf3d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = get_trimmed_articles(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "32b9eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book 3 Ultra hands-on: NVIDIA R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US, Netherlands and Japan reportedly agree to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia CEO says AI will need regulation, socia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweden to upgrade Berzelius supercomputer with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChatGPT's massive hype has made these 5 artifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>How Nvidia’s CUDA Monopoly in Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>GPUs for Deep Learning in 2023 – An In-depth A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>GPUs for Deep Learning in 2023 – An In-depth A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>GPUs for Deep Learning in 2023 – An In-depth A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>GPUs for Deep Learning in 2023 – An In-depth A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "0    Samsung Galaxy Book 3 Ultra hands-on: NVIDIA R...\n",
       "1    US, Netherlands and Japan reportedly agree to ...\n",
       "2    Nvidia CEO says AI will need regulation, socia...\n",
       "3    Sweden to upgrade Berzelius supercomputer with...\n",
       "4    ChatGPT's massive hype has made these 5 artifi...\n",
       "..                                                 ...\n",
       "544  How Nvidia’s CUDA Monopoly in Machine Learning...\n",
       "570  GPUs for Deep Learning in 2023 – An In-depth A...\n",
       "670  GPUs for Deep Learning in 2023 – An In-depth A...\n",
       "770  GPUs for Deep Learning in 2023 – An In-depth A...\n",
       "870  GPUs for Deep Learning in 2023 – An In-depth A...\n",
       "\n",
       "[156 rows x 1 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "783770d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = resp['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "be3fad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, response = generate_questions(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "24f59184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. What processor and graphics card does the Galaxy Book 3 Ultra feature? \\n2. How light is the Galaxy Book 3 Ultra?\\n3. What features does the Samsung Multi Control feature support on PCs and smartphones?'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5160b88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6k2Cxr1QrjaR7P3wB4y9as1UG07Um at 0x7f33f9546110> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" What processor and graphics card does the Galaxy Book 3 Ultra feature? \\n2. How light is the Galaxy Book 3 Ultra?\\n3. What features does the Samsung Multi Control feature support on PCs and smartphones?\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1676429595,\n",
       "  \"id\": \"cmpl-6k2Cxr1QrjaR7P3wB4y9as1UG07Um\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 43,\n",
       "    \"prompt_tokens\": 1032,\n",
       "    \"total_tokens\": 1075\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7cf68886",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers, response_a = generate_answers(prompt1, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a0369bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The Galaxy Book 3 Ultra features 13th-gen Intel Core i5 or i7 processors, with Iris X graphics and up to 32GB of DDR5 RAM, as well as NVIDIA’s RTX 4050 and 4070 graphics cards.\\n2. The Galaxy Book 3 Ultra is 1.79kg (3.9 pounds) in weight and 16.5mm (0.64 inches) thin.\\n3. The Samsung Multi Control feature supports recent websites, instant hotspot, a keyboard and trackpad across PCs and smartphones.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3e0de356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6k2DyTMyc07ijLQN4rzLKFacaZHvS at 0x7f33f6329030> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The Galaxy Book 3 Ultra features 13th-gen Intel Core i5 or i7 processors, with Iris X graphics and up to 32GB of DDR5 RAM, as well as NVIDIA\\u2019s RTX 4050 and 4070 graphics cards.\\n2. The Galaxy Book 3 Ultra is 1.79kg (3.9 pounds) in weight and 16.5mm (0.64 inches) thin.\\n3. The Samsung Multi Control feature supports recent websites, instant hotspot, a keyboard and trackpad across PCs and smartphones.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1676429658,\n",
       "  \"id\": \"cmpl-6k2DyTMyc07ijLQN4rzLKFacaZHvS\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 109,\n",
       "    \"prompt_tokens\": 1085,\n",
       "    \"total_tokens\": 1194\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356cf44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
